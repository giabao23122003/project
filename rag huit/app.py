
import os
import json
import gradio as gr
from langchain.chat_models import ChatOpenAI
from langchain.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.docstore.document import Document
from langchain.chains import RetrievalQA

# Thi·∫øt l·∫≠p API Key (b·∫°n n√™n d√πng bi·∫øn m√¥i tr∆∞·ªùng)
os.environ["OPENAI_API_KEY"] = "your-api-keykey"  # Thay b·∫±ng API key th·∫≠t

# B∆∞·ªõc 1: Load d·ªØ li·ªáu JSON
with open("cam_nang_tuyen_sinh_2.json", "r", encoding="utf-8") as f:
    raw_data = json.load(f)

documents = [Document(page_content=entry["content"], metadata={"title": entry["title"]}) for entry in raw_data]

# B∆∞·ªõc 2: T√°ch vƒÉn b·∫£n
splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = splitter.split_documents(documents)

# B∆∞·ªõc 3: T·∫°o vector store v·ªõi FAISS
embeddings = OpenAIEmbeddings()
vectorstore = FAISS.from_documents(docs, embeddings)

# B∆∞·ªõc 4: T·∫°o RetrievalQA chain
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(temperature=0, model="gpt-4"),
    retriever=vectorstore.as_retriever(search_type="similarity", k=3)
)

# B∆∞·ªõc 5: H√†m x·ª≠ l√Ω c√¢u h·ªèi t·ª´ ng∆∞·ªùi d√πng
def chatbot_fn(query):
    return qa_chain.run(query)

# Giao di·ªán Gradio
gr.Interface(
    fn=chatbot_fn,
    inputs="text",
    outputs="text",
    title="ü§ñ Chatbot T∆∞ V·∫•n Tuy·ªÉn Sinh - HUIT",
    description="Nh·∫≠p c√¢u h·ªèi v·ªÅ ph∆∞∆°ng th·ª©c x√©t tuy·ªÉn, h·ªçc b·ªïng, ng√†nh h·ªçc,..."
).launch()
